{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary libraries\n",
    "\n",
    "This step involves importing the required libraries for data manipulation, visualization, machine learning utilities, and TensorFlow for building the GRU model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Importing machine learning utilities\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importing TensorFlow libraries for building the GRU model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GRU,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data\n",
    "\n",
    "In this step, we load the training, testing, and validation datasets from their respective CSV files using Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"./data/train.csv\"\n",
    "test_file_path = \"./data/test.csv\"\n",
    "val_file_path = \"./data/val.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file_path, on_bad_lines=\"skip\")\n",
    "test_df = pd.read_csv(test_file_path, on_bad_lines=\"skip\")\n",
    "val_df = pd.read_csv(val_file_path, on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Validation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "\n",
    "In this step, we remove any rows with missing values from the training, testing, and validation datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "val_df = val_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the hadling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Filtering\n",
    "\n",
    "In this step, we filter the rows of the datasets to include only those with valid gender values. We define the set of valid gender values as \"Male\", \"Female\", and \"Non-binary\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid gender values\n",
    "valid_genders = {\"Male\", \"Female\", \"Non-binary\"}\n",
    "\n",
    "# Filter rows where 'Gender' is in the set of valid genders\n",
    "train_df = train_df[train_df[\"Gender\"].isin(valid_genders)]\n",
    "test_df = test_df[test_df[\"Gender\"].isin(valid_genders)]\n",
    "val_df = val_df[val_df[\"Gender\"].isin(valid_genders)]\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Type Conversion\n",
    "\n",
    "In this step, we convert the data types of certain columns to ensure consistency and suitability for analysis:\n",
    "\n",
    "- Convert 'User_ID' to integer.\n",
    "- Convert 'Age' to numeric, replacing non-numeric values with NaN, then to integer.\n",
    "- Drop rows with NaN values in the 'Age' column.\n",
    "- Convert 'Gender', 'Platform', and 'Dominant_Emotion' columns to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'User_ID' to int\n",
    "train_df[\"User_ID\"] = train_df[\"User_ID\"].astype(int)\n",
    "test_df[\"User_ID\"] = test_df[\"User_ID\"].astype(int)\n",
    "val_df[\"User_ID\"] = val_df[\"User_ID\"].astype(int)\n",
    "\n",
    "# Convert 'Age' to numeric, replacing non-numeric values with NaN\n",
    "train_df[\"Age\"] = pd.to_numeric(train_df[\"Age\"], errors=\"coerce\")\n",
    "test_df[\"Age\"] = pd.to_numeric(test_df[\"Age\"], errors=\"coerce\")\n",
    "val_df[\"Age\"] = pd.to_numeric(val_df[\"Age\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with NaN values in the 'Age' column\n",
    "train_df = train_df.dropna(subset=[\"Age\"])\n",
    "test_df = test_df.dropna(subset=[\"Age\"])\n",
    "val_df = val_df.dropna(subset=[\"Age\"])\n",
    "\n",
    "# Convert 'Age' to int\n",
    "train_df[\"Age\"] = train_df[\"Age\"].astype(int)\n",
    "test_df[\"Age\"] = test_df[\"Age\"].astype(int)\n",
    "val_df[\"Age\"] = val_df[\"Age\"].astype(int)\n",
    "\n",
    "# Convert 'Gender', 'Platform', and 'Dominant_Emotion' to str\n",
    "train_df[\"Gender\"] = train_df[\"Gender\"].astype(str)\n",
    "test_df[\"Gender\"] = test_df[\"Gender\"].astype(str)\n",
    "val_df[\"Gender\"] = val_df[\"Gender\"].astype(str)\n",
    "\n",
    "train_df[\"Platform\"] = train_df[\"Platform\"].astype(str)\n",
    "test_df[\"Platform\"] = test_df[\"Platform\"].astype(str)\n",
    "val_df[\"Platform\"] = val_df[\"Platform\"].astype(str)\n",
    "\n",
    "train_df[\"Dominant_Emotion\"] = train_df[\"Dominant_Emotion\"].astype(str)\n",
    "test_df[\"Dominant_Emotion\"] = test_df[\"Dominant_Emotion\"].astype(str)\n",
    "val_df[\"Dominant_Emotion\"] = val_df[\"Dominant_Emotion\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Label Encoding\n",
    "\n",
    "In this step, we ensure consistent label encoding for the target variable ('Dominant_Emotion') across all data splits:\n",
    "\n",
    "- We use a LabelEncoder to encode the target variable.\n",
    "- Labels from the training, testing, and validation sets are combined to create a unified label encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that we use consistent label encoding for the target variable across all data splits\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all the labels from train, test, and validation sets to create a unified label encoder\n",
    "all_labels = (\n",
    "    list(train_df[\"Dominant_Emotion\"])\n",
    "    + list(test_df[\"Dominant_Emotion\"])\n",
    "    + list(val_df[\"Dominant_Emotion\"])\n",
    ")\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# list(train_df[\"Dominant_Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_df[\"Dominant_Emotion\"])[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Encoding Target Variable and Splitting Features\n",
    "\n",
    "In this step, we encode the target variable ('Dominant_Emotion') into numerical values using the previously fitted label encoder. Then, we split the datasets into features (X) and target (y):\n",
    "\n",
    "- Encode the target variable into numerical values for training, testing, and validation sets.\n",
    "- Split the datasets into features (X) and target (y) by dropping the 'Dominant_Emotion' column.\n",
    "- Identify the numeric columns in the feature datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = label_encoder.transform(train_df[\"Dominant_Emotion\"])\n",
    "y_test_encoded = label_encoder.transform(test_df[\"Dominant_Emotion\"])\n",
    "y_val_encoded = label_encoder.transform(val_df[\"Dominant_Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and target variable for each dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Dominant_Emotion\", axis=1)\n",
    "X_test = test_df.drop(\"Dominant_Emotion\", axis=1)\n",
    "X_val = val_df.drop(\"Dominant_Emotion\", axis=1)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Feature Scaling\n",
    "\n",
    "In this step, we standardize the numeric features using StandardScaler:\n",
    "\n",
    "- Identify the numeric columns in the feature datasets.\n",
    "- Scale the features using StandardScaler separately for training, testing, and validation sets.\n",
    "- Verify the scaling by displaying a sample of the scaled features from the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_columns])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_columns])\n",
    "X_val_scaled = scaler.transform(X_val[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the scaling\n",
    "print(\"Scaled feature sample (first 5 rows of the training data):\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Build the GRU Model\n",
    "\n",
    "In this step, we build the GRU (Gated Recurrent Unit) model using TensorFlow's Keras API:\n",
    "\n",
    "- Define a Sequential model.\n",
    "- Reshape the input data to fit the GRU layer.\n",
    "- Add a GRU layer with 128 units and return sequences.\n",
    "- Apply a dropout layer with a dropout rate of 0.2.\n",
    "- Add a dense layer with 64 units and ReLU activation.\n",
    "- Finally, add a dense output layer with the number of units equal to the number of classes in the target variable and softmax activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Reshape((1, X_train_scaled.shape[1]),\n",
    "                input_shape=(X_train_scaled.shape[1],)),\n",
    "        GRU(units=128, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(len(label_encoder.classes_), activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "\n",
    "Below is the summary of the GRU model architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Compile the Model\n",
    "\n",
    "In this step, we compile the GRU model:\n",
    "\n",
    "- We use the Adam optimizer.\n",
    "- The loss function is set to sparse categorical crossentropy, suitable for multi-class classification tasks.\n",
    "- We track accuracy as a metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile the Model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Set up TensorBoard Callback and Train the Model\n",
    "\n",
    "In this step, we set up TensorBoard callback to visualize the training process:\n",
    "\n",
    "- Define the directory where TensorBoard logs will be stored.\n",
    "- Set up the TensorBoard callback to monitor training progress and visualize it using TensorBoard.\n",
    "- Train the GRU model using the training data and validate it on the validation data.\n",
    "- We train the model for 200 epochs with a batch size of 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Set up TensorBoard callback\n",
    "log_dir = \"./logs\"  # Directory where TensorBoard logs will be stored\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Step 7: Train the Model with TensorBoard callback\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_encoded,\n",
    "    validation_data=(X_val_scaled, y_val_encoded),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Evaluate the Model\n",
    "\n",
    "In this step, we evaluate the trained GRU model on the test dataset to assess its performance:\n",
    "\n",
    "- Compute the test loss and accuracy using the test dataset.\n",
    "- Print out the test loss and accuracy metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Final Results Visualization and Analysis\n",
    "\n",
    "In this step, we make predictions on the validation dataset using the trained model and visualize the confusion matrix:\n",
    "\n",
    "- Predict the labels for the validation dataset using the trained GRU model.\n",
    "- Decode the predicted labels back to their original emotion labels using the label encoder.\n",
    "- Compute the confusion matrix using the true and predicted labels.\n",
    "- Visualize the confusion matrix using a heatmap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Validation Data\n",
    "\n",
    "In this step, we make predictions on the validation dataset using the trained GRU model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Predicted Labels\n",
    "\n",
    "In this step, we decode the predicted labels back to their original emotion labels using the label encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the maximum probability for each sample\n",
    "y_pred_labels = np.argmax(y_pred, axis=2)\n",
    "\n",
    "# Flatten the array\n",
    "y_pred_val_encoded = y_pred_labels.flatten()\n",
    "\n",
    "# Convert the flat array of labels to their corresponding emotion labels using the label encoder\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_val_encoded)\n",
    "\n",
    "# Reshape the array back to its original shape\n",
    "y_pred_labels = y_pred_labels.reshape(y_pred.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Unique Labels\n",
    "\n",
    "In this step, we obtain the unique emotion labels from the validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = list(val_df[\"Dominant_Emotion\"])\n",
    "unique_labels = np.unique(y_val)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "In this step, we compute the confusion matrix using the true and predicted labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_val_encoded, y_pred_val_encoded)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Confusion Matrix Heatmap\n",
    "\n",
    "In this step, we visualize the confusion matrix using a heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    cf_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    xticklabels=unique_labels,\n",
    "    yticklabels=unique_labels,\n",
    "    cmap=\"Blues\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "In this step, we calculate and display a classification report, which includes precision, recall, and F1-score for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_rep = classification_report(\n",
    "    y_val_encoded, y_pred_val_encoded, target_names=unique_labels\n",
    ")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Plot Over Epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Hyperparameter Tuning\n",
    "\n",
    "In this step, we experiment with different hyperparameters (e.g., dropout rates) to optimize the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Experimenting with different dropout rates\n",
    "dropout_rates = [0.1, 0.2, 0.3]\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Reshape(\n",
    "                (1, X_train_scaled.shape[1]), input_shape=(X_train_scaled.shape[1],)\n",
    "            ),\n",
    "            GRU(units=128, return_sequences=True),\n",
    "            Dropout(rate),  # Try different dropout rates\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(len(label_encoder.classes_), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_encoded,\n",
    "        validation_data=(X_val_scaled, y_val_encoded),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        verbose=0,  # Suppress output for brevity\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded, verbose=0)\n",
    "    print(f\"Dropout Rate: {rate}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Cross-Validation\n",
    "\n",
    "In this step, we perform k-fold cross-validation to obtain a more robust estimate of the model's performance and assess its generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Example: Perform 5-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train_scaled, y_train_encoded):\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "\n",
    "    # Define and compile the model (same as before)\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Reshape(\n",
    "                (1, X_train_scaled.shape[1]), input_shape=(X_train_scaled.shape[1],)\n",
    "            ),\n",
    "            GRU(units=128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(len(label_encoder.classes_), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=200, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the model on validation fold\n",
    "    _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate mean and standard deviation of accuracies\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}, Standard Deviation: {std_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
